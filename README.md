<div id="top"></div>
<div align="center">
  <img src="docs/imgs/lagent_logo.png" width="450"/>

[![docs](https://img.shields.io/badge/docs-latest-blue)](https://lagent.readthedocs.io/en/latest/)
[![PyPI](https://img.shields.io/pypi/v/lagent)](https://pypi.org/project/lagent)
[![license](https://img.shields.io/github/license/InternLM/lagent.svg)](https://github.com/InternLM/lagent/tree/main/LICENSE)
[![issue resolution](https://img.shields.io/github/issues-closed-raw/InternLM/lagent)](https://github.com/InternLM/lagent/issues)
[![open issues](https://img.shields.io/github/issues-raw/InternLM/lagent)](https://github.com/InternLM/lagent/issues)
![Visitors](https://api.visitorbadge.io/api/visitors?path=InternLM%2Flagent%20&countColor=%23263759&style=flat)
![GitHub forks](https://img.shields.io/github/forks/InternLM/lagent)
![GitHub Repo stars](https://img.shields.io/github/stars/InternLM/lagent)
![GitHub contributors](https://img.shields.io/github/contributors/InternLM/lagent)

English | [ÁÆÄ‰Ωì‰∏≠Êñá](README_zh-CN.md) | [Êó•Êú¨Ë™û](README_ja_JP.md) | [‡§π‡§ø‡§Ç‡§¶‡•Ä](README_in_HIN.md) | [‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ](README_in_beng.md) | [ÌïúÍµ≠Ïñ¥](README_KR_Kr.md)

</div>

<p align="center">
    üëã join us on <a href="https://twitter.com/intern_lm" target="_blank">ùïè (Twitter)</a>, <a href="https://discord.gg/xa29JuW87d" target="_blank">Discord</a> and <a href="https://r.vansin.top/?r=internwx" target="_blank">WeChat</a>
</p>

## What's Lagent?

Lagent is a lightweight open-source framework that allows users to efficiently build large language model(LLM)-based agents. It also provides some typical tools to augment LLM. The overview of our framework is shown below:

![image](https://github.com/InternLM/lagent/assets/24351120/cefc4145-2ad8-4f80-b88b-97c05d1b9d3e)

## üíªTech Stack

<p>
  <a href="">
    <img src="https://img.shields.io/badge/Python-007ACC?style=for-the-badge&logo=python&logoColor=yellow" alt="python" />
  </a>

### Major Features

**0.1.2** was released in 24/10/2023:

- **Support an efficient inference engine.** Lagent now supports efficient inference engine [lmdeploy turbomind](https://github.com/InternLM/lmdeploy/tree/main).

- **Support multiple kinds of agents out of the box.** Lagent now supports [ReAct](https://arxiv.org/abs/2210.03629), [AutoGPT](https://github.com/Significant-Gravitas/Auto-GPT) and [ReWOO](https://arxiv.org/abs/2305.18323), which can drive the large language models(LLMs) for multiple trials of reasoning and function calling.

- **Extremely simple and easy to extend.** The framework is quite simple with a clear structure. With only 20 lines of code, you are able to construct your own agent. It also supports three typical tools: Python interpreter, API call, and google search.

- **Support various large language models.** We support different LLMs, including API-based (GPT-3.5/4) and open-source (LLaMA 2, InternLM) models.

## Getting Started

Please see the [overview](docs/en/get_started/overview.md) for the general introduction of Lagent. Meanwhile, we provide extremely simple code for quick start. You may refer to [examples](examples/) for more details.

### Installation

Install with pip (Recommended).

```bash
pip install lagent
```

Optionally, you could also build Lagent from source in case you want to modify the code:

```bash
git clone https://github.com/InternLM/lagent.git
cd lagent
pip install -e .
```

### Run ReAct Web Demo

```bash
# You need to install streamlit first
# pip install streamlit
streamlit run examples/react_web_demo.py
```

Then you can chat through the UI shown as below
![image](https://github.com/InternLM/lagent/assets/24622904/3aebb8b4-07d1-42a2-9da3-46080c556f68)

### Run a ReWOO agent with GPT-3.5

Below is an example of running ReWOO with GPT-3.5

```python
# Import necessary modules and classes from the "lagent" library.
from lagent.agents import ReWOO
from lagent.actions import ActionExecutor, GoogleSearch, LLMQA
from lagent.llms import GPTAPI

# Initialize the Language Model (llm) and provide your API key.
llm = GPTAPI(model_type='gpt-3.5-turbo', key=['Your OPENAI_API_KEY'])

# Initialize the Google Search tool and provide your API key.
search_tool = GoogleSearch(api_key='Your SERPER_API_KEY')

# Initialize the LLMQA tool using the Language Model (llm).
llmqa_tool = LLMQA(llm)

# Create a chatbot by configuring the ReWOO agent.
chatbot = ReWOO(
    llm=llm,  # Provide the Language Model instance.
    action_executor=ActionExecutor(
        actions=[search_tool, llmqa_tool]  # Specify the actions the chatbot can perform.
    ),
)

# Ask the chatbot a question and store the response.
response = chatbot.chat('What profession does Nicholas Ray and Elia Kazan have in common')

# Print the chatbot's response.
print(response.response)  # Output the response generated by the chatbot.
>>> Film director.
```

### Run a ReAct agent with InternLM

NOTE: If you want to run a HuggingFace model, please run `pip install -e .[all]` first.

```python
# Import necessary modules and classes from the "lagent" library.
from lagent.agents import ReAct
from lagent.actions import ActionExecutor, GoogleSearch, PythonInterpreter
from lagent.llms import HFTransformer

# Initialize the HFTransformer-based Language Model (llm) and provide the model name.
llm = HFTransformer('internlm/internlm-chat-7b-v1_1')

# Initialize the Google Search tool and provide your API key.
search_tool = GoogleSearch(api_key='Your SERPER_API_KEY')

# Initialize the Python Interpreter tool.
python_interpreter = PythonInterpreter()

# Create a chatbot by configuring the ReAct agent.
chatbot = ReAct(
    llm=llm,  # Provide the Language Model instance.
    action_executor=ActionExecutor(
        actions=[search_tool, python_interpreter]  # Specify the actions the chatbot can perform.
    ),
)
# Ask the chatbot a mathematical question in LaTeX format.
response = chatbot.chat('Ëã•$z=-1+\sqrt{3}i$,Âàô$\frac{z}{{z\overline{z}-1}}=\left(\ \ \right)$')

# Print the chatbot's response.
print(response.response)  # Output the response generated by the chatbot.
>>> $-\\frac{1}{3}+\\frac{{\\sqrt{3}}}{3}i$
```

## Citation

If you find this project useful in your research, please consider cite:

```latex
@misc{lagent2023,
    title={{Lagent: InternLM} a lightweight open-source framework that allows users to efficiently build large language model(LLM)-based agents},
    author={Lagent Developer Team},
    howpublished = {\url{https://github.com/InternLM/lagent}},
    year={2023}
}
```

## License

This project is released under the [Apache 2.0 license](LICENSE).

<p align="right"><a href="#top">üîº Back to top</a></p>
